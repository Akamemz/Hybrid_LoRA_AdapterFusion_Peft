{
  "experiment_name": "ba_lora_75k",
  "timestamp": "2025-10-16T15:26:26.037141",
  "duration_seconds": 2208.84564,
  "config": {
    "model": "distilbert-base-uncased",
    "dataset": "sst2",
    "peft_method": "ba_lora",
    "epochs": 3,
    "batch_size": 16,
    "learning_rate": 5e-05,
    "seed": 42,
    "max_length": 128,
    "ba_lora_config": {
      "base_rank": 8,
      "gradient_samples": 1000,
      "use_warmstart": true,
      "alpha": 16
    }
  },
  "model_info": {
    "total_parameters": 67620868,
    "trainable_parameters": 665858,
    "frozen_parameters": 66955010,
    "peft_parameters": 73728,
    "added_parameters": 73728,
    "task_head_parameters": 592130,
    "trainable_percentage": 0.9846930684178736,
    "parameter_efficiency": 99.01530693158213,
    "budget_usage_percentage": 98.304,
    "budget_remaining": 1272,
    "within_budget": true
  },
  "eval_results": {
    "eval_loss": 0.28570279479026794,
    "eval_accuracy": 0.8853,
    "eval_f1": 0.8886,
    "eval_precision": 0.8789,
    "eval_recall": 0.8986,
    "eval_runtime": 5.8916,
    "eval_samples_per_second": 148.006,
    "eval_steps_per_second": 9.335,
    "epoch": 3.0
  },
  "parameter_budget": {
    "target": 75000,
    "used": 73728,
    "usage_percentage": 98.304,
    "within_budget": true
  }
}