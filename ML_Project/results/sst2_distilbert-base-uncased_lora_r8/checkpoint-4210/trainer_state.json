{
  "best_global_step": 4210,
  "best_metric": 0.28028979897499084,
  "best_model_checkpoint": "/Users/timurabdygulov/Documents/GitHub/Hybrid_LoRA-Data-Centric_Improvements/ML_Project/results/sst2_distilbert-base-uncased_lora_r8/checkpoint-4210",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4210,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 1.274478554725647,
      "learning_rate": 4.9608076009501194e-05,
      "loss": 0.6292,
      "step": 100
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 1.9673714637756348,
      "learning_rate": 4.921219319081552e-05,
      "loss": 0.3756,
      "step": 200
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.4013283252716064,
      "learning_rate": 4.8816310372129854e-05,
      "loss": 0.3233,
      "step": 300
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.5720536708831787,
      "learning_rate": 4.842042755344418e-05,
      "loss": 0.3668,
      "step": 400
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.710692882537842,
      "learning_rate": 4.8024544734758514e-05,
      "loss": 0.3386,
      "step": 500
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.8209140300750732,
      "learning_rate": 4.762866191607284e-05,
      "loss": 0.3636,
      "step": 600
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.7254226207733154,
      "learning_rate": 4.7232779097387175e-05,
      "loss": 0.3191,
      "step": 700
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 2.1523780822753906,
      "learning_rate": 4.683689627870151e-05,
      "loss": 0.3321,
      "step": 800
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 3.7675588130950928,
      "learning_rate": 4.6441013460015835e-05,
      "loss": 0.3575,
      "step": 900
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 4.1181864738464355,
      "learning_rate": 4.604513064133017e-05,
      "loss": 0.3112,
      "step": 1000
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.154846668243408,
      "learning_rate": 4.5649247822644495e-05,
      "loss": 0.3141,
      "step": 1100
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 2.5980968475341797,
      "learning_rate": 4.525336500395883e-05,
      "loss": 0.2721,
      "step": 1200
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.5558831691741943,
      "learning_rate": 4.4857482185273156e-05,
      "loss": 0.3166,
      "step": 1300
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 4.84277868270874,
      "learning_rate": 4.446159936658749e-05,
      "loss": 0.2973,
      "step": 1400
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 4.379382133483887,
      "learning_rate": 4.406571654790182e-05,
      "loss": 0.3031,
      "step": 1500
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 1.0758798122406006,
      "learning_rate": 4.366983372921615e-05,
      "loss": 0.2878,
      "step": 1600
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.3256688117980957,
      "learning_rate": 4.3273950910530483e-05,
      "loss": 0.3144,
      "step": 1700
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 2.181724786758423,
      "learning_rate": 4.287806809184482e-05,
      "loss": 0.302,
      "step": 1800
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.0175093412399292,
      "learning_rate": 4.248218527315915e-05,
      "loss": 0.3063,
      "step": 1900
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 2.670928478240967,
      "learning_rate": 4.208630245447348e-05,
      "loss": 0.305,
      "step": 2000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 2.288891553878784,
      "learning_rate": 4.169041963578781e-05,
      "loss": 0.3169,
      "step": 2100
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 2.0391316413879395,
      "learning_rate": 4.1294536817102145e-05,
      "loss": 0.2936,
      "step": 2200
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 2.5684101581573486,
      "learning_rate": 4.089865399841647e-05,
      "loss": 0.2561,
      "step": 2300
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 3.533267021179199,
      "learning_rate": 4.0502771179730805e-05,
      "loss": 0.2691,
      "step": 2400
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 2.245142936706543,
      "learning_rate": 4.010688836104513e-05,
      "loss": 0.285,
      "step": 2500
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 2.230543851852417,
      "learning_rate": 3.9711005542359465e-05,
      "loss": 0.3082,
      "step": 2600
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.6138834953308105,
      "learning_rate": 3.931512272367379e-05,
      "loss": 0.291,
      "step": 2700
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.327930212020874,
      "learning_rate": 3.8919239904988126e-05,
      "loss": 0.3044,
      "step": 2800
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.4143102169036865,
      "learning_rate": 3.852335708630246e-05,
      "loss": 0.2968,
      "step": 2900
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.4532694816589355,
      "learning_rate": 3.8127474267616786e-05,
      "loss": 0.2895,
      "step": 3000
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 2.4225847721099854,
      "learning_rate": 3.773159144893112e-05,
      "loss": 0.302,
      "step": 3100
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.6271460056304932,
      "learning_rate": 3.7335708630245446e-05,
      "loss": 0.3235,
      "step": 3200
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 4.168035984039307,
      "learning_rate": 3.693982581155978e-05,
      "loss": 0.2724,
      "step": 3300
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 3.4027984142303467,
      "learning_rate": 3.654394299287411e-05,
      "loss": 0.2941,
      "step": 3400
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 2.551152229309082,
      "learning_rate": 3.614806017418844e-05,
      "loss": 0.2977,
      "step": 3500
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.4584944248199463,
      "learning_rate": 3.5752177355502774e-05,
      "loss": 0.305,
      "step": 3600
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 0.770797610282898,
      "learning_rate": 3.53562945368171e-05,
      "loss": 0.2833,
      "step": 3700
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.166243076324463,
      "learning_rate": 3.4960411718131434e-05,
      "loss": 0.278,
      "step": 3800
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.9145365953445435,
      "learning_rate": 3.456452889944576e-05,
      "loss": 0.2481,
      "step": 3900
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.869080901145935,
      "learning_rate": 3.4168646080760095e-05,
      "loss": 0.2842,
      "step": 4000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.0572636127471924,
      "learning_rate": 3.377276326207443e-05,
      "loss": 0.271,
      "step": 4100
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 3.141223192214966,
      "learning_rate": 3.3376880443388755e-05,
      "loss": 0.2847,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8772935779816514,
      "eval_loss": 0.28028979897499084,
      "eval_runtime": 4.4569,
      "eval_samples_per_second": 195.653,
      "eval_steps_per_second": 12.341,
      "step": 4210
    }
  ],
  "logging_steps": 100,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2268641077951488.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
