{
  "best_global_step": 4210,
  "best_metric": 0.28028979897499084,
  "best_model_checkpoint": "/Users/timurabdygulov/Documents/GitHub/Hybrid_LoRA-Data-Centric_Improvements/ML_Project/results/sst2_distilbert-base-uncased_lora_r8/checkpoint-4210",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 1.274478554725647,
      "learning_rate": 4.9608076009501194e-05,
      "loss": 0.6292,
      "step": 100
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 1.9673714637756348,
      "learning_rate": 4.921219319081552e-05,
      "loss": 0.3756,
      "step": 200
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.4013283252716064,
      "learning_rate": 4.8816310372129854e-05,
      "loss": 0.3233,
      "step": 300
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 1.5720536708831787,
      "learning_rate": 4.842042755344418e-05,
      "loss": 0.3668,
      "step": 400
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.710692882537842,
      "learning_rate": 4.8024544734758514e-05,
      "loss": 0.3386,
      "step": 500
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.8209140300750732,
      "learning_rate": 4.762866191607284e-05,
      "loss": 0.3636,
      "step": 600
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.7254226207733154,
      "learning_rate": 4.7232779097387175e-05,
      "loss": 0.3191,
      "step": 700
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 2.1523780822753906,
      "learning_rate": 4.683689627870151e-05,
      "loss": 0.3321,
      "step": 800
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 3.7675588130950928,
      "learning_rate": 4.6441013460015835e-05,
      "loss": 0.3575,
      "step": 900
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 4.1181864738464355,
      "learning_rate": 4.604513064133017e-05,
      "loss": 0.3112,
      "step": 1000
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.154846668243408,
      "learning_rate": 4.5649247822644495e-05,
      "loss": 0.3141,
      "step": 1100
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 2.5980968475341797,
      "learning_rate": 4.525336500395883e-05,
      "loss": 0.2721,
      "step": 1200
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 2.5558831691741943,
      "learning_rate": 4.4857482185273156e-05,
      "loss": 0.3166,
      "step": 1300
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 4.84277868270874,
      "learning_rate": 4.446159936658749e-05,
      "loss": 0.2973,
      "step": 1400
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 4.379382133483887,
      "learning_rate": 4.406571654790182e-05,
      "loss": 0.3031,
      "step": 1500
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 1.0758798122406006,
      "learning_rate": 4.366983372921615e-05,
      "loss": 0.2878,
      "step": 1600
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.3256688117980957,
      "learning_rate": 4.3273950910530483e-05,
      "loss": 0.3144,
      "step": 1700
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 2.181724786758423,
      "learning_rate": 4.287806809184482e-05,
      "loss": 0.302,
      "step": 1800
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.0175093412399292,
      "learning_rate": 4.248218527315915e-05,
      "loss": 0.3063,
      "step": 1900
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 2.670928478240967,
      "learning_rate": 4.208630245447348e-05,
      "loss": 0.305,
      "step": 2000
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 2.288891553878784,
      "learning_rate": 4.169041963578781e-05,
      "loss": 0.3169,
      "step": 2100
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 2.0391316413879395,
      "learning_rate": 4.1294536817102145e-05,
      "loss": 0.2936,
      "step": 2200
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 2.5684101581573486,
      "learning_rate": 4.089865399841647e-05,
      "loss": 0.2561,
      "step": 2300
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 3.533267021179199,
      "learning_rate": 4.0502771179730805e-05,
      "loss": 0.2691,
      "step": 2400
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 2.245142936706543,
      "learning_rate": 4.010688836104513e-05,
      "loss": 0.285,
      "step": 2500
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 2.230543851852417,
      "learning_rate": 3.9711005542359465e-05,
      "loss": 0.3082,
      "step": 2600
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 2.6138834953308105,
      "learning_rate": 3.931512272367379e-05,
      "loss": 0.291,
      "step": 2700
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.327930212020874,
      "learning_rate": 3.8919239904988126e-05,
      "loss": 0.3044,
      "step": 2800
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 2.4143102169036865,
      "learning_rate": 3.852335708630246e-05,
      "loss": 0.2968,
      "step": 2900
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.4532694816589355,
      "learning_rate": 3.8127474267616786e-05,
      "loss": 0.2895,
      "step": 3000
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 2.4225847721099854,
      "learning_rate": 3.773159144893112e-05,
      "loss": 0.302,
      "step": 3100
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.6271460056304932,
      "learning_rate": 3.7335708630245446e-05,
      "loss": 0.3235,
      "step": 3200
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 4.168035984039307,
      "learning_rate": 3.693982581155978e-05,
      "loss": 0.2724,
      "step": 3300
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 3.4027984142303467,
      "learning_rate": 3.654394299287411e-05,
      "loss": 0.2941,
      "step": 3400
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 2.551152229309082,
      "learning_rate": 3.614806017418844e-05,
      "loss": 0.2977,
      "step": 3500
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.4584944248199463,
      "learning_rate": 3.5752177355502774e-05,
      "loss": 0.305,
      "step": 3600
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 0.770797610282898,
      "learning_rate": 3.53562945368171e-05,
      "loss": 0.2833,
      "step": 3700
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.166243076324463,
      "learning_rate": 3.4960411718131434e-05,
      "loss": 0.278,
      "step": 3800
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.9145365953445435,
      "learning_rate": 3.456452889944576e-05,
      "loss": 0.2481,
      "step": 3900
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.869080901145935,
      "learning_rate": 3.4168646080760095e-05,
      "loss": 0.2842,
      "step": 4000
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.0572636127471924,
      "learning_rate": 3.377276326207443e-05,
      "loss": 0.271,
      "step": 4100
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 3.141223192214966,
      "learning_rate": 3.3376880443388755e-05,
      "loss": 0.2847,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8772935779816514,
      "eval_loss": 0.28028979897499084,
      "eval_runtime": 4.4569,
      "eval_samples_per_second": 195.653,
      "eval_steps_per_second": 12.341,
      "step": 4210
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 3.848052740097046,
      "learning_rate": 3.298099762470309e-05,
      "loss": 0.2889,
      "step": 4300
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 3.1890299320220947,
      "learning_rate": 3.258511480601742e-05,
      "loss": 0.3017,
      "step": 4400
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.5673003196716309,
      "learning_rate": 3.2189231987331756e-05,
      "loss": 0.2674,
      "step": 4500
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 5.222131252288818,
      "learning_rate": 3.179334916864608e-05,
      "loss": 0.2685,
      "step": 4600
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 2.161618232727051,
      "learning_rate": 3.1397466349960416e-05,
      "loss": 0.2561,
      "step": 4700
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 2.2524287700653076,
      "learning_rate": 3.100158353127474e-05,
      "loss": 0.2796,
      "step": 4800
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 4.230650901794434,
      "learning_rate": 3.060570071258908e-05,
      "loss": 0.2918,
      "step": 4900
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.9616330862045288,
      "learning_rate": 3.0209817893903407e-05,
      "loss": 0.2795,
      "step": 5000
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 1.7839677333831787,
      "learning_rate": 2.9813935075217737e-05,
      "loss": 0.279,
      "step": 5100
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 0.9742898344993591,
      "learning_rate": 2.941805225653207e-05,
      "loss": 0.2715,
      "step": 5200
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 2.9811806678771973,
      "learning_rate": 2.9022169437846397e-05,
      "loss": 0.2797,
      "step": 5300
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 2.6424477100372314,
      "learning_rate": 2.862628661916073e-05,
      "loss": 0.2751,
      "step": 5400
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 2.8163626194000244,
      "learning_rate": 2.8230403800475058e-05,
      "loss": 0.264,
      "step": 5500
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 2.1354784965515137,
      "learning_rate": 2.783452098178939e-05,
      "loss": 0.2715,
      "step": 5600
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 2.9390170574188232,
      "learning_rate": 2.7438638163103725e-05,
      "loss": 0.2602,
      "step": 5700
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 3.358246326446533,
      "learning_rate": 2.7042755344418052e-05,
      "loss": 0.2425,
      "step": 5800
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 2.3765289783477783,
      "learning_rate": 2.6646872525732385e-05,
      "loss": 0.2815,
      "step": 5900
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 2.8924875259399414,
      "learning_rate": 2.6250989707046712e-05,
      "loss": 0.2466,
      "step": 6000
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.8983099460601807,
      "learning_rate": 2.5855106888361046e-05,
      "loss": 0.2711,
      "step": 6100
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 3.9189226627349854,
      "learning_rate": 2.5459224069675376e-05,
      "loss": 0.2514,
      "step": 6200
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 3.5200252532958984,
      "learning_rate": 2.506334125098971e-05,
      "loss": 0.2613,
      "step": 6300
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 8.958297729492188,
      "learning_rate": 2.466745843230404e-05,
      "loss": 0.2707,
      "step": 6400
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 1.2938079833984375,
      "learning_rate": 2.427157561361837e-05,
      "loss": 0.2884,
      "step": 6500
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 3.237495183944702,
      "learning_rate": 2.38756927949327e-05,
      "loss": 0.2465,
      "step": 6600
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 1.4134005308151245,
      "learning_rate": 2.3479809976247034e-05,
      "loss": 0.2532,
      "step": 6700
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 4.224265098571777,
      "learning_rate": 2.3083927157561364e-05,
      "loss": 0.2764,
      "step": 6800
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 3.5110981464385986,
      "learning_rate": 2.2688044338875694e-05,
      "loss": 0.2848,
      "step": 6900
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 2.0541725158691406,
      "learning_rate": 2.2292161520190024e-05,
      "loss": 0.2435,
      "step": 7000
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 2.8434557914733887,
      "learning_rate": 2.1896278701504354e-05,
      "loss": 0.2364,
      "step": 7100
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 3.042985677719116,
      "learning_rate": 2.1500395882818685e-05,
      "loss": 0.2831,
      "step": 7200
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 3.4225876331329346,
      "learning_rate": 2.1104513064133015e-05,
      "loss": 0.2686,
      "step": 7300
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 1.680942177772522,
      "learning_rate": 2.070863024544735e-05,
      "loss": 0.2437,
      "step": 7400
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 1.985785961151123,
      "learning_rate": 2.031274742676168e-05,
      "loss": 0.2588,
      "step": 7500
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 2.2672741413116455,
      "learning_rate": 1.9916864608076012e-05,
      "loss": 0.2599,
      "step": 7600
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 1.3864755630493164,
      "learning_rate": 1.9520981789390342e-05,
      "loss": 0.2706,
      "step": 7700
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 3.210967779159546,
      "learning_rate": 1.9125098970704672e-05,
      "loss": 0.2417,
      "step": 7800
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 2.649754285812378,
      "learning_rate": 1.8729216152019003e-05,
      "loss": 0.2571,
      "step": 7900
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 3.21573805809021,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.2713,
      "step": 8000
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 2.378249406814575,
      "learning_rate": 1.7937450514647666e-05,
      "loss": 0.2789,
      "step": 8100
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 2.5564191341400146,
      "learning_rate": 1.7541567695961997e-05,
      "loss": 0.2309,
      "step": 8200
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 2.939850330352783,
      "learning_rate": 1.7145684877276327e-05,
      "loss": 0.2514,
      "step": 8300
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 1.6547355651855469,
      "learning_rate": 1.6749802058590657e-05,
      "loss": 0.26,
      "step": 8400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8818807339449541,
      "eval_loss": 0.28311797976493835,
      "eval_runtime": 4.1821,
      "eval_samples_per_second": 208.509,
      "eval_steps_per_second": 13.151,
      "step": 8420
    }
  ],
  "logging_steps": 100,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4537282155902976.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
