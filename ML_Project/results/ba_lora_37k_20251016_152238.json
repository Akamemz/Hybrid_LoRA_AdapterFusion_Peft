{
  "experiment_name": "ba_lora_37k",
  "timestamp": "2025-10-16T14:44:44.623396",
  "duration_seconds": 2273.616575,
  "config": {
    "model": "distilbert-base-uncased",
    "dataset": "sst2",
    "peft_method": "ba_lora",
    "epochs": 3,
    "batch_size": 16,
    "learning_rate": 5e-05,
    "seed": 42,
    "max_length": 128,
    "ba_lora_config": {
      "base_rank": 4,
      "gradient_samples": 1000,
      "use_warmstart": true,
      "alpha": 8
    }
  },
  "model_info": {
    "total_parameters": 67584004,
    "trainable_parameters": 628994,
    "frozen_parameters": 66955010,
    "peft_parameters": 36864,
    "added_parameters": 36864,
    "task_head_parameters": 592130,
    "trainable_percentage": 0.9306847223789818,
    "parameter_efficiency": 99.06931527762102,
    "budget_usage_percentage": 98.304,
    "budget_remaining": 636,
    "within_budget": true
  },
  "eval_results": {
    "eval_loss": 0.2846720218658447,
    "eval_accuracy": 0.8865,
    "eval_f1": 0.8901,
    "eval_precision": 0.8775,
    "eval_recall": 0.9032,
    "eval_runtime": 7.1552,
    "eval_samples_per_second": 121.869,
    "eval_steps_per_second": 7.687,
    "epoch": 3.0
  },
  "parameter_budget": {
    "target": 37500,
    "used": 36864,
    "usage_percentage": 98.304,
    "within_budget": true
  }
}